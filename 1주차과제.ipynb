{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차과제.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXJ0bjNVb+7ZM69+nyoPvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kim43/kim-sia/blob/master/1%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXnb8lOAaAoo",
        "colab_type": "text"
      },
      "source": [
        "#인공지능 사관학교 프리코스 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDkgqOMoyYTd",
        "colab_type": "text"
      },
      "source": [
        "##1주차 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT2SxgQ534Q4",
        "colab_type": "text"
      },
      "source": [
        "######언어, 음성, 이미지, 자율주행 분야의 기술을 사용하는 4가지 제품 및 서비스"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dekldHhBdASz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "* 언어 : 번역      \n",
        "\n",
        "&nbsp; 인공신경망 번역은 인공지능이 스스로 빅데이터를 학습하고 번역하는 최신 번역 기술이다. 이는 문장을 통째로 번역하는 방식으로 과거의 몇개의 단어가 모여 구 단위로 쪼개 번역하던 통계 기반 번역과는 다르다. 인공지능이 전체 문맥을 파악한 뒤 문장 안에서 단어와 순서, 문맥, 의미에서의 차이 등을 반영해 번역한다.     \n",
        "\n",
        "&nbsp; 인공지능 방식이 적용 되기 전에는 규칙기반번역이 활용 되었다. 컴퓨터는 한국어와 영어 간 주어, 서술어 순서가 다른 점을 감안하여 이를 재배열하여 번역한다. 이 다음으로 적용된 방식이 통계기반번역이다. 인공지능에 보다 가까워진 방식으로 특정 단어가 통계적으로 많이 쓰이는 뜻으로 컴퓨터가 찾아 해석 결과를 내놓는 방식이다. 예를들면, you의 경우 여러 뜻이 있지만 한국인들이 '너'라는 단어를 많이 쓴다는 점을 고려해 번역한다.     \n",
        "\n",
        "&nbsp; 인공신경망 번역은 문장 단위로 컴퓨터가 인식한다. *문장이 입력되면 이 문장을 가상 공간의 하나의 점을 의미하는 벡터와 같은 숫자로 변환하고, 학습 데이터를 통해 배운 가중치를 더해 번역한다.* 벡터에는 단어와 구절, 어순 정보까지 다 들어 있다. 문장 정보를 숫자로 바꾼 벡터에 'cat' 이라는 단어 벡터가 1000차원 공간 안에서 어떤 위치에 있다면, 'kitten' 이라는 단어 벡터는 그 옆에 위치한다고 볼 수 있다. 비슷한 의미를 지닌 단어들을 가까운 위치에 배치하도록 자동 학습하기 때문에, 'cat'과 'kitten'이 유의어라는 사실을 인지하고 번역한다. 그러나 통계기반번역은 빈도수를 기반으로 이뤄지기 때문에 인터넷 상에 'cat' 이라는 단어만 많고 'kitten'이라는 단어가 별로 없다면 'kitten' 이라는 단어를 제대로 번역하지 못한다.         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KSR4521oW2V",
        "colab_type": "text"
      },
      "source": [
        "* 음성 : AI 스피커      \n",
        "\n",
        "&nbsp; AI 스피커에 인간의 목소리가 마이크를 통해 입력되면 '스피치 프로세서'가 음성 신호를 음성 신호 벡터로 변화시킨다. 음성 신호 벡터는 '스피치 인식기'와 '언어 특징 추출기'를 통해 '언어 표현 정보'로 추출된다. 여기서 언어 표현 정보는 기존의 단어 관련 정보를 고려하여 추출된다.    \n",
        "&nbsp; 예를 들어, AI 스피커에 '음악 틀어줘' 라는 명령을 내렸을 때 먼저 음성 신호 '음악 틀어줘'가 전체 음성 신호 벡터로 표현된 후, 단어 DB를 기반으로 분할된다. 이 분할된 음성 신호 벡터는 단어마다 고정된 길이의 하위 음성 신호 벡터인 언어 표현 정보로 추출된다. 이렇게 추출된 언어 표현 정보는 '스킬 분류기', '의도 분류기', 및 '슬롯 인지기'로 입력된다.    \n",
        "먼저 스킬 분류기는 언어 표현 정보를 통해 입력된 명령에 알맞은 스킬을 결정할 수 있다. 스킬은 음악, 쇼핑 등 해당 명령과 관련된 가장 상위 카테고리 일 수 있으며, 때로는 명령에 따라 복수의 스킬과 관련성을 가질 수도 있다.   \n",
        "의도 분류기는 언어 표현 정보를 통해 입력된 명령의 의도를 결정할 수 있다.   \n",
        "슬롯 인지기는 언어 표현 정보에서 의미 있는 정보와 문장의 문법적 구조를 고려하여 의도/명령의 핵심 정보를 슬롯으로서 찾아 인지한다.   \n",
        "이렇게 분류 및 인지를 마친 스킬, 의도, 슬롯은 '스킬 프로세서'를 거쳐 명령 수행을 위한 관련 기기를 동작시킨다.      \n",
        "\n",
        "&nbsp; AI 스피커가 입력된 언어를 제대로 이해하기 위해서는 스킬, 의도, 슬롯에 대한 정확한 분석이 선행돼야 한다. 때문에 의도 분류기는 입력된 데이터를 기반으로 학습이 가능하다. '인공 뉴럴 네트워크'와 '딥 뉴럴 네트워크'를 사용할 수 있는 의도 분류기는 축적되는 데이터에 따라 뉴럴 네트워크의 변화하는 가중치를 감지하고, 이를 학습해 보다 정확하게 명령의 의도를 판단할 수 있게 된다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVqCu25eociN",
        "colab_type": "text"
      },
      "source": [
        "* 이미지 : Face ID   \n",
        "   \n",
        "&nbsp; Face ID는 iphone과 ipad에서 사용되는 얼굴 인식을 이용한 보안 기술로, 등록되어 있던 사용자의 얼굴 데이터와 현재 인식되고 있는 얼굴을 대조해 즉시 사용자를 인식하는 시스템이다.      \n",
        "\n",
        "&nbsp; 기존 Touch ID는 손에 이물질이 묻거나 땀이 있으면 인식률이 급격하게 떨어졌으나 Face ID는 얼굴 형태만 변형되지 않으면 잠금이 해제되며 일반적인 카메라 얼굴인식이나 홍채인식 방식보다 잠금 해제 속도와 인식률 모두 훨씬 우수하다. 그러나 땀이나 이물질이 묻지 않는 한 손가락만 홈 버튼에 갖다 대면 잠금이 해제되는 Touch ID와 달리 마스크나 큰 모자를 착용해 안면의 상당 부분을 가리거나 과도한 표정을 지어 얼굴이 많이 일그러지는 경우 인식률이 급격히 저하된다.        \n",
        "   \n",
        "&nbsp; Face ID는 iphone이나 ipad의 도트 프로젝터로 보이지 않는 3만 개의 점을 사용자의 얼굴에 투사해 사용자의 특징적인 얼굴 패턴을 매핑한 다음 수학적으로 변화시켜 secure enclave 에 저장하고 이를 뉴럴 엔진으로 분석한다. 이 덕분에 외모가 바뀌어도 인식에 실패하지 않으며 얼굴을 인식할 때는 적외선 일루미네이터와 TrueDepth 카메라로 데이터와 대조해 얼굴을 식별한다. 단순한 카메라 촬영이 아닌 적외선 일루미네이터를 사용하는 만큼 어두운 곳에서 더 인식률이 높으며 평면이 아니라 얼굴의 곡면을 스캔하기 때문에 사진으로는 무력화되지 않는다.   \n",
        "또 머신러닝 기술을 사용하여 사용할수록 인식률이 높아지고 빨라지며 약 6주 정도 사용하면 인식률의 최대치에 도달하여 일부 불가능한 상황을 제외한 거의 모든 상황에서 실패없이 인식한다. 사용자가 수염을 기르든 각양각색의 안경이나 선글라스를 쓰든, 머리 스타일을 바꾸든, 모자를 쓰든, 화장을 하거나 안하든 머신 러닝을 통해 이를 인식하고 데이터를 업데이트한다.   \n",
        "이를 통해 인식률이 떨어져 잠금 해제가 안되는 경우에 비밀번호를 계속 입력해 계속 얼굴 데이터를 보강하면 인식률이 점차 개선될 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xff6tdyqw4su",
        "colab_type": "text"
      },
      "source": [
        "* 자율주행 : 엔드투엔드 자율 주행      \n",
        "\n",
        "&nbsp; 인공지능 시스템을 통한 완전 자율 주행 자동차는 운전자의 운전 조작이 전혀 없이 자동차 스스로 주행 환경을 인식해 목표 지점까지 운행함에 따라 운전자의 부주의로 인한 교통사고를 미연에 예방하고, 편리한 운전 환경을 제공할 수 있게 된다.      \n",
        "\n",
        "&nbsp; 자동차용 인공지능 모듈에는 머신러닝, 자연어 처리, 이미지 처리, 음성 인식 등의 모듈이 있다. 자동차용 인공지능 시스템은 라이다 센서, 레이더, 초음파 센서, 적외선 카메라, 모노/스테레오 카메라 등을 자동차 내외부에 설치하고 이러한 센서 등을 통해 외부 정보를 수집해 분석한 수 자동차 스스로 주변 환경을 인식해 위험한 상황을 판단하고 주행 경로를 계획하는 등 운전자의 주행 조작을 최소화하며, 스스로 안전한 주행이 가능하도록 해주는 시스템이다.      \n",
        "\n",
        "&nbsp; 자율 주행 자동차의 원리는 크게 인지, 판단, 제어로 나뉜다.   \n",
        "인지단계에서는 GPS와 카메라, 레이더 등을 활용해 주변 상황의 정보를 인식하고 수집한다. 카메라를 통해 입력된 이미지에 딥러닝을 적용하면 자율 주행 시스템에 필요한 정적 환경 정보와 동적 환경 요소를 전부 검출, 분류할 수 있다.     \n",
        "판단단계에서는 인지 정보를 바탕으로 주행 전략을 결정한다. 자동차가 어떤 환경에 놓여 있는지를 파악하고 이미지를 분석한 후, 주행 환경과 목표지점에 적합한 주행 전략을 수립하고 판단하게 된다.   \n",
        "제어단계에서는 엔진 구동과 주행 방향 등을 결정하며 본격적으로 주행을 시작하게 된다. 이 단계에서 딥러닝을 응용할 수도 있다. 딥러닝 기술을 활용해 개개인의 운전 방식을 데이터화하면 인간 감성을 고려한 차량 제어가 가능하다. 단순 자율 주행 기능뿐 아니라 탑승자의 안색, 음성, 상태 등을 인식하고 개별 탑승자에게 맞춤형 편의 기술을 제공하는 서비스에도 딥러닝이 적용 될 수 있다.     \n",
        "자율 주행 자동차는 끊임없이 인지-판단-제어 단계를 반복하며 소프트웨어가 자율 주행 자동차에 명령을 하고 자율 주행 자동차는 그 명령에 따라 주행하는 것이다.       \n",
        "\n",
        "&nbsp; 인지-판단-제어로 분류되는 자율 주행 자동차의 기능은 모두 사람이 설계한 범위 안에서 작동하기 때문에 설계 시점에서 예상치 못한 상황에 적절히 대처할 수 없다. '엔드투엔드 자율주행'은 운전의 전 과정을 통째로 학습하는 딥러닝 방식이다. 엔드투엔드 방식을 자율주행 자동차에 적용하면 새로운 운행 환경에 대한 추가 기능이 필요할 때마다 인지-판단-제어 알고리즘을 다시 설계하거나 변경하지 않고, 새로운 상황에 대한 데이터를 추가적으로 학슴함으로써 자율주행 시스템을 구현할 수 있다.      \n",
        "엔드투엔드 학습 방식에는 운전자의 운행 방식을 데이터로 수집하고 이를 모방하는 학습 방식과 시뮬레이터를 이용해 가장 최적화된 운전 방식을 스스로 학습하는 강화학습 기반 방식이 있다."
      ]
    }
  ]
}
